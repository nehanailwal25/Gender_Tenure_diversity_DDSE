{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca5a77a",
   "metadata": {},
   "source": [
    "# Extracting Users Full names from github usernames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f9f43",
   "metadata": {},
   "source": [
    "## Doing web scrapping for getting user's fullnames (Using BeautifulSoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a12a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the useful Liberaries\n",
    "\n",
    "pip install requests beautifulsoup4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the useful Liberaries \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import xlsxwriter\n",
    "\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the Users CSV file that was downloaded from GHTorrent to get the usernames \n",
    "\n",
    "df = pd.read_csv(r\"E:\\Data\\Datasets\\users_dataset.csv\");\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb8844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the specific column from dataframe \"df\"\n",
    "\n",
    "names_arr = []\n",
    "\n",
    "df_array= df.loc[:,\"Username\"].to_numpy()\n",
    "df_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a049004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing web scrapping for getting user's fullmanes from github.com\n",
    "\n",
    "for i in df_array:\n",
    "    url = f\"https://github.com/{i}\"\n",
    "    html_content = requests.get(url)\n",
    "    html_content_text = html_content.text\n",
    "    soup = BeautifulSoup(html_content_text, \"lxml\")\n",
    "    #if soup.find('span') is None:\n",
    "    #    names_arr.append(f\"{i}\")\n",
    "    if(html_content.status_code == 200 and html_content_text):\n",
    "        name_tag = soup.find('span', itemprop='name').text\n",
    "        names_arr.append(name_tag)\n",
    "    else:\n",
    "        names_arr.append(\"NA\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bab25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing the extracted fullnames in a seperate excel file\n",
    "\n",
    "workbook = xlsxwriter.Workbook('users_fullnames.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "for i in range(len(names_arr)):\n",
    "    worksheet.write(i, 0, names_arr[i])\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8e3550",
   "metadata": {},
   "source": [
    "#### After extracting the fullnames for all the needed users the data is combined in the main excel and fullnames are divided into firstname and lastname for better processing by using excel data cleaning process and easy prediction of user's gender "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
